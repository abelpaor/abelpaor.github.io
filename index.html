<!DOCTYPE html>
<!-- based on https://pages-themes.github.io/minimal/ -->
<html lang="en-US">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Abel Pacheco Ortega</title>
  <meta name="generator" content="Jekyll v3.9.3">
  <meta property="og:title" content="Minimal theme">
  <meta property="og:locale" content="en_US">
  <meta name="description" content="Minimal is a theme for GitHub Pages.">
  <meta property="og:description" content="Minimal is a theme for GitHub Pages.">
  <link rel="canonical" href="https://pages-themes.github.io/minimal/">
  <meta property="og:url" content="https://pages-themes.github.io/minimal/">
  <meta property="og:site_name" content="Minimal theme">
  <meta property="og:type" content="website">
  <meta name="twitter:card" content="summary">
  <meta property="twitter:title" content="Minimal theme">
  <script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","description":"Minimal is a theme for GitHub Pages.","headline":"Minimal theme","name":"Minimal theme","publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://pages-themes.github.io/minimal/assets/img/logo.png"}},"url":"https://pages-themes.github.io/minimal/"}</script>
  <!-- End Jekyll SEO tag -->


  <link rel="stylesheet" href="./assets/css/style.css">
  <!--[if lt IE 9]>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js"></script>
    <![endif]-->
  <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

  <!-- Setup Google Analytics -->



  <!-- You can set your favicon here -->
  <!-- link rel="shortcut icon" type="image/x-icon" href="/minimal/favicon.ico" -->

  <!-- end custom head snippets -->

</head>

<body>
  <div class="wrapper">
    <header>
      <h1><a>Abel <br />Pacheco Ortega</a></h1>
      <h2>Research Engineer</h2>
      <img src="./assets/imgs/profile.png" alt="Abel Pacheco-Ortega" class="profile-pic">
      <p style="text-align: justify;">
        I am a committed individual with a focus on applied computer vision and machine learning. I enjoy working in
        multidisciplinary teams and contributing to scalable, high-quality systems.
      </p>
      <p>
      <table class="hidden-table">
        <tr>
          <td width="20 px">
            <img src="assets/imgs/contact/mail.png" width="15 px" />
          </td>
          <td>

            <a href="mailto:abel.pachecoortega@outlook.com">abel.pachecoortega@outlook.com</a>
          </td>
        </tr>
        <tr>
          <td width="20 px">
            <img src="assets/imgs/contact/linkedin.png" width="15 px" />
          </td>
          <td>
            <a href="https://www.linkedin.com/in/abelpachecoortega" target="_blank">abelpachecoortega</a>
          </td>
        </tr>
        <tr>
          <td width="20 px">
            <img src="assets/imgs/contact/github-circle.png" width="15 px" />
          </td>
          <td>
            <a href="https://github.com/dougbel" target="_blank">dougbel</a>
          </td>
        </tr>
      </table>
      </p>


      <!-- <p class="view"><a href="https://github.com/pages-themes/minimal">View the Project on GitHub
          <small>pages-themes/minimal</small></a></p> -->

      <!-- <ul class="downloads">
        <li><a href="https://github.com/pages-themes/minimal/zipball/master">Download <strong>ZIP File</strong></a></li>
        <li><a href="https://github.com/pages-themes/minimal/tarball/master">Download <strong>TAR Ball</strong></a></li>
        <li><a href="https://github.com/pages-themes/minimal">View On <strong>GitHub</strong></a></li>
      </ul> -->

      <p>
      <h3>
        <!-- <a href="#about">About</a><br /> -->
        <a href="#education">Education</a><br />
        <a href="#experience">Experience</a><br />
        <a href="#projects">Projects</a><br />
        <a href="#publications">Publications</a><br />
        <a href="#teaching">Teaching</a><br />
      </h3>
      </p>



    </header>
    <section>

      <!-- <h2 id="about" class="sections">About</h2>
      I am a passionate individual with a focus on applied computer vision and machine learning. I enjoy working in
      multidisciplinary teams and contributing to scalable, high-quality systems.
      <br />
      <br /> -->


      <h2 id="education" class="sections">Education</h2>
      <table class="hidden-table">
        <tr>
          <th rowspan="2" style="width: 50px;"><img src="assets/imgs/education/uob.png" width="30px"></th>
          <th>PhD (Computer Science)</th>
          <th style="text-align: right;">2018 – 2023</th>
        </tr>
        <tr>
          <td colspan="3">University of Bristol<br />
        </tr>
        <tr>
          <td colspan="3">
            Developed methods for visual affordance recognition by combining 3D geometry with generative models to model
            human-environment interactions. Focused on one-shot learning using variational techniques. Conducted
            large-scale distributed evaluations using MPI on high-performance computing infrastructure.
            <br />
            <small>
              <i>Keywords</i>: Machine Learning, Computer Vision, Statistics, Data Analysis, Scientific Writing,
              Collegiality, Scene understanding, 3D features, Distributed Systems, Message Passing Interface (MPI),
              CVAE,
              AWS (S3, Mechanical Turk)
            </small>
          </td>
        </tr>
      </table>
      <table class="hidden-table">
        <tr>
          <th rowspan="2" style="width: 50px;"><img src="assets/imgs/education/unam.png" width="30px"></th>
          <th>Master in Engineering (Computing)</th>
          <th style="text-align: right;">2009 – 2011</th>
        </tr>
        <tr>
          <td colspan="3">Universidad Nacional Autónoma de México<br />
        </tr>
        <tr>
          <td colspan="3">
            Implemented a visual place recognition and topological mapping system using RGB-D data. Created a custom
            feature detector (FAST+3D) and a viewpoint-invariant descriptor, integrated into a robot localization
            framework for indoor navigation.
            <br />
            <small>
              <i>Keywords</i>: 3D vision, RGB-D, Feature description, Feature detection, Visual SLAM, Mobile robotics,
              Robot localization
            </small>
          </td>
        </tr>
      </table>
      <table class="hidden-table">
        <tr>
          <th rowspan="2" style="width: 50px;"><img src="assets/imgs/education/unam.png" width="30px"></th>
          <th>Bachelor of Computer Engineering</th>
          <th style="text-align: right;">2009 – 2011</th>
        </tr>
        <tr>
          <td colspan="3">Universidad Nacional Autónoma de México<br />
        </tr>
        <tr>
          <td colspan="3">
            Designed and developed an information system to automate the planning and management of engineering field
            trips. The system streamlined authorisation and reporting processes for over 6,000 students per year,
            improving efficiency and access to real-time data.
            <br />
            <small>
              <i>Keywords</i>: Systems development, Process automation, Database design, Web technologies, Information
              systems, Software engineering
            </small>
          </td>
        </tr>
      </table>

      <h2 id="experience" class="sections">Experience</h2>
      <table class="hidden-table">
        <tr>
          <th>Computer Vision Research Engineer </th>
          <th style="text-align: right;">January 2024 – April 2025</th>
        </tr>
        <tr>
          <td colspan="2">Beam (formerly Rovco/Vaarst)<br />
        </tr>
        <tr>
          <td colspan="2">
            <ul class="compact">
              <li>Evaluated new technologies in machine learning and computer vision for product integration, ensuring
                robustness in uncertain conditions.</li>
              <li>Developed tools for visualising and validating calibration accuracy.</li>
              <li>Evaluated loop closure detection algorithms for the Beam SLAM system using proprietary stereo cameras.
              </li>
              <li>Proposed a camera focus verification method to ensure precise focal alignment.</li>
            </ul>
            <small>
              <i>Keywords</i>: Critical Analysis, Statistical Frameworks, Loop Closure Detection, Camera Calibration,
              Simultaneous Localization and Mapping (SLAM), Deep Learning, Computer Vision, Robotics, C++, Python
            </small>
          </td>
        </tr>
      </table>
      <table class="hidden-table">
        <tr>
          <th>Head of Systems Development</th>
          <th style="text-align: right;">2013 – 2017</th>
        </tr>
        <tr>
          <td colspan="2">National Institute for the Evaluation of Education (INEE), México<br />
        </tr>
        <tr>
          <td colspan="2">
            <ul class="compact">
              <li>Led the planning and execution of national-level digital systems for education evaluation.</li>
              <li>Directed software development, system architecture, and team coordination.</li>
              <li>Applied agile methodologies to multiple concurrent projects.</li>
              <li>Oversaw risk management and automation improvements.</li>
            </ul>
            <small>
              <i>Keywords</i>: Agile Frameworks, Project Management, Team Leadership, Collaboration, Java, PostgreSQL,
              Linux, Risk Management
            </small>
          </td>
        </tr>
      </table>
      <table class="hidden-table">
        <tr>
          <th>Lecturer / Teaching Assistant (Part-Time)</th>
          <th style="text-align: right;">2013 – 2023</th>
        </tr>
        <tr>
          <td colspan="2">University of Bristol / Universidad Nacional Autónoma de México<br />
        </tr>
        <tr>
          <td colspan="2">
            <ul class="compact">
              <li>Delivered academic instruction and supported student learning in Programming, Image Processing, and
                Computer Vision.</li>
              <li>Examined over 10 Master's theses in Computer Vision topics, providing research and technical guidance.
              </li>
              <li>Participated in curriculum development and coordination, incorporating modern computer vision
                techniques.</li>
              <li>Mentored students on complex technical projects, fostering critical thinking and enhancing their
                ability to communicate technical concepts effectively through reports and presentations.</li>
            </ul>
            <small>
              <i>Keywords</i>: Teaching, Python, C++, Computer Vision, Academic Evaluation, Research Supervision
            </small>
          </td>
        </tr>
      </table>
      <table class="hidden-table">
        <tr>
          <th>Research Developer (Part-time)</th>
          <th style="text-align: right;">2013 – 2017</th>
        </tr>
        <tr>
          <td colspan="2">Universidad Nacional Autónoma de México<br />
        </tr>
        <tr>
          <td colspan="2">
            <ul class="compact">
              <li>Designed and implemented high- and low-level computer vision modules for a general-purpose robot.</li>
              <li>Developed visual pipelines with real-time performance constraints in robotics systems.</li>
              <li>Adapted state-of-the-art algorithms for autonomous robotic tasks.</li>
              <li>Enhanced perception system reliability and robustness through effective integration with downstream
                systems, enabling consistent performance in dynamic environments</li>
            </ul>
            <small>
              <i>Keywords</i>: C++, 3D Vision, OpenCV, ROS, Linux, Robotics, Systems Integration
            </small>
          </td>
        </tr>
      </table>

      <h2 id="projects" class="sections">Projects</h2>
      <table class="hidden-table">
        <tr>
          <td rowspan="2" width="180 px" style="text-align: left;"><img src="assets/imgs/projects/aros.png"
              width="150px"></td>
          <td><b>AROS: Affordance recognition with one-shot human stances </b></td>
        </tr>
        <tr>
          <td>
            AROS is a one-shot learning method for predicting how highly-articulated human poses
            interact with 3D scenes. The key idea is to model human-scene interactions using only a few pose examples,
            without needing to retrain the model for new interactions. Given a 3D mesh of an unseen environment, AROS
            predicts where interactions (affordances) can occur and generates realistic 3D human poses in context.
            <br />
            <small>
              </i>Keywords</i>: Affordances, Scene understanding, 3D descriptor, human interactions, visual perception,
              Python
            </small>
            <ul class="downloads">
              <li>
                <a href="https://abelpaor.github.io/AROS/" target="_blank">
                  <img src="assets/imgs/contact/languages.png" width="20">
                  <strong>Webpage</strong></a>
              </li>
              <li>
                <a href="https://youtu.be/VgbD9NZwmws" target="_blank">
                  <img src="assets/imgs/contact/youtube.png" width="20">
                  <strong>Youtube</strong></a>
              </li>
              <li>
                <a href="https://github.com/abelpaor/AROS" target="_blank">
                  <img src="assets/imgs/contact/github-circle.png" width="20">
                  <br /><strong>GitHub</strong>
                </a>
              </li>
            </ul>

          </td>

        </tr>
      </table>
      <table class="hidden-table">
        <tr>
          <td><b>General Porpouse Service Robot (Justina) </b></td>
          <td rowspan="2" width="180 px" style="text-align: right;"><img src="assets/imgs/projects/justina.png"
              width="150px"></td>
        </tr>
        <tr>
          <td>
            Robot Justina is a multidisciplinary project designed to assist people in domestic
            environments. To achieve this, it uses advanced technologies such as speech recognition, computer vision,
            autonomous navigation, and object manipulation.
            I contributed to the design, implementation, and improvement of the perception system focusing on computer
            vision. <br />
            <small>
              </i>Keywords</i>: Machine learning, Computer Vision, OpenCV, C++, Service Robots, Object Recognition, ROS
              (Robot Operating System), Multidisciplinary Projects
            </small>
            <ul class="downloads">
              <li>
                <a href="https://biorobotics.fi-p.unam.mx/robot-justina/" target="_blank">
                  <img src="assets/imgs/contact/languages.png" width="20">
                  <strong>Webpage</strong></a>
              </li>
              <li>
                <a href="https://www.youtube.com/@BioroboticsUNAM" target="_blank">
                  <img src="assets/imgs/contact/youtube.png" width="20">
                  <strong>Youtube</strong></a>
              </li>
              <li><a href="https://github.com/RobotJustina" target="_blank"><img
                    src="assets/imgs/contact/github-circle.png" width="20">
                  <br /><strong>GitHub</strong></a></li>
            </ul>

          </td>

        </tr>
      </table>
      <table class="hidden-table">
        <tr>
          <td rowspan="2" width="180 px" style="text-align: left;"><img src="assets/imgs/projects/autonomos.png"
              width="150px"></td>
          <td><b>Vision-Based Lane Detection for Scale Model Autonomous Cars </b></td>
        </tr>
        <tr>
          <td>
            As part of the AutoModelCar challenge at the Robotics Mexican Tournament (TMR), which extends the
            <a href="https://www.fu-berlin.de/en/presse/informationen/fup/2016/fup_16_271-autonome-modellautos-universitaet-mexiko/index.html"
              target="_blank">Urban Mobility Visions initiative</a> by Dr. Raúl Rojas (Freie Universität Berlin), this
            project focuses on developing a ROS-based visual lane detector for 1:10 scale autonomous vehicles. The
            system processes camera input to estimate the vehicle’s position within the lane and assist with path
            following. <br />
            <small style="color: #069;">
              </i>Keywords</i>: Computer Vision, OpenCV, C++, ROS (Robot Operating System), Autonomous driving
            </small>
            <ul class="downloads">
              <li>
                <a href="https://www.femexrobotica.org/tmr2018/portfolio-item/autos-autonomos/" target="_blank">
                  <img src="assets/imgs/contact/languages.png" width="20">
                  <strong>Webpage</strong></a>
              </li>
              <li>
                <a href="https://www.youtube.com/watch?v=_G4Cx42j8V4&t=12s" target="_blank">
                  <img src="assets/imgs/contact/youtube.png" width="20">
                  <strong>Youtube</strong></a>
              </li>
              <li><a href="https://github.com/dougbel/automodel_lines_detector" target="_blank"><img
                    src="assets/imgs/contact/github-circle.png" width="20">
                  <br /><strong>GitHub</strong></a></li>
            </ul>

          </td>

        </tr>
      </table>

      <h2 id="publications" class="sections">Publications</h2>
      <table class="papers-table">
        <tr>
          <td width="40 px">
            <a href="https://abelpaor.github.io/AROS/" target="_blank">
              <img src="assets/imgs/publications/icon.png" width="20 px" />
            </a>
          </td>
          <td>
            Pacheco-Ortega, A., & Mayol-Cuevas, W. (2023). <i>AROS: Affordance recognition with one-shot human
              stances</i>. <i><b>Frontiers in Robotics and AI, 10</b></i>, 1076780. <a
              href="https://doi.org/10.3389/frobt.2023.1076780"
              target="_blank">https://doi.org/10.3389/frobt.2023.1076780</a>
          </td>
        </tr>

        <tr>
          <td>
            <a href="https://ieeexplore.ieee.org/document/8733651" target="_blank">
              <img src="assets/imgs/publications/icon.png" width="20 px" />
            </a>
          </td>
          <td>
            Sarmiento, C., Savage, J., Juarez, A., Contreras, L., Pacheco, A., & Matamoros, M. (2019, April). <i>Feature
              detection using Hidden Markov Models for 3D-visual recognition</i>. In <i><b>2019 IEEE International
                Conference on Autonomous Robot Systems and Competitions (ICARSC)</b></i> (pp. 1–6). IEEE. <a
              href="https://doi.org/10.1109/ICARSC.2019.8733651"
              target="_blank">https://doi.org/10.1109/ICARSC.2019.8733651</a>
          </td>
        </tr>

        <tr>
          <td>
            <a href="https://arxiv.org/abs/1809.03210" target="_blank">
              <img src="assets/imgs/publications/icon.png" width="20 px" />
            </a>
          </td>
          <td>
            Pacheco, A., Estrada, H., Vázquez, E., Martell, R., Hernández, J., Cruz, J., Silva, E., Savage, J., &
            Contreras, L. (2018). <i>Intelligent flat-and-textureless object manipulation in service robots</i>. In
            <i><b>IROS 2018 Workshop: Towards Robots that Exhibit Manipulation Intelligence</b></i>, <i><b>IEEE/RSJ
                International Conference on Intelligent Robots and Systems (IROS)</b></i>, Madrid, Spain. <a
              href="https://doi.org/10.48550/arXiv.1809.03210"
              target="_blank">https://doi.org/10.48550/arXiv.1809.03210</a>
          </td>
        </tr>

        <tr>
          <td>
            <a href="https://www.researchgate.net/publication/300474195_Construction_of_Roadmaps_for_Mobile_Robots%27_Navigation_Using_RGB-D_Cameras"
              target="_blank">
              <img src="assets/imgs/publications/icon.png" width="20 px" />
            </a>
          </td>
          <td>
            Savage, J., Contreras, L., Figueroa, I., Pacheco, A., Bermudez, A., Negrete, M., & Rivera, C. (2016).
            <i>Construction of roadmaps for mobile robots’ navigation using RGB-D cameras</i>. In <i><b>Intelligent
                Autonomous Systems 13: Proceedings of the 13th International Conference IAS-13</b></i> (pp. 217–229).
            Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-08338-4_17"
              target="_blank">https://doi.org/10.1007/978-3-319-08338-4_17</a>
          </td>
        </tr>

        <tr>
          <td>
            <a href="https://www.researchgate.net/publication/271549068_Object_detection_via_receptive_field_co-occurrence_and_spatial_cloud-point_data"
              target="_blank">
              <img src="assets/imgs/publications/icon.png" width="20 px" />
            </a>
          </td>
          <td>
            Contreras, L. A., Pacheco-Ortega, A., Figueroa, J. I., Mayol-Cuevas, W. W., & Savage, J. (2013, November).
            <i>Object detection via receptive field co-occurrence and spatial cloud-point data</i>. In <i><b>2013 16th
                International Conference on Advanced Robotics (ICAR)</b></i> (pp. 1–8). IEEE. <a
              href="https://doi.org/10.1109/ICAR.2013.6766575"
              target="_blank">https://doi.org/10.1109/ICAR.2013.6766575</a>
          </td>
        </tr>

        <tr>
          <td>
            <a href="https://link.springer.com/chapter/10.1007/978-3-642-32060-6_37" target="_blank">
              <img src="assets/imgs/publications/icon.png" width="20 px" />
            </a>
          </td>
          <td>
            Figueroa, J., Contreras, L., Pacheco, A., & Savage, J. (2012). <i>Development of an object recognition and
              location system using the Microsoft Kinect™ sensor</i>. In T. Röfer, N. M. Mayer, J. Savage, & U. Saranlı
            (Eds.), <i><b>RoboCup 2011: Robot Soccer World Cup XV</b></i> (Lecture Notes in Computer Science, Vol. 7416,
            pp. 321–328). Springer. <a href="https://doi.org/10.1007/978-3-642-32060-6_37"
              target="_blank">https://doi.org/10.1007/978-3-642-32060-6_37</a>
          </td>
        </tr>
      </table>

      <h2 id="teaching" class="sections">Teaching</h2>
      <table class="hidden-table">
        <tr>
          <td colspan="2" style="border-bottom: 1px solid #e5e5e5; padding: 5px 0px;">
            <b>Lecturer</b>
          </td>
        </tr>
        <tr>
          <td width="30px" style="vertical-align: top;  padding: 10px 0px;">
            <img src="assets/imgs/education/unam.png" width="30px" />
          </td>
          <td style="vertical-align: top;  padding: 10px 0px;">
            <b>Universidad Nacional Autónoma de México</b>
            <br />
            Postgraduate Program in Engineering
            <dl>
              <dd>
                Computer Vision
                <ul class="compact">
                  <li>Term 2018-2</li>
                  <li>Term 2012-2</li>
                </ul>
              </dd>
            </dl>

            Postgraduate Program in Computer Science and Engineering
            <br />
            <dd>
              Computer Vision
              <ul class="compact">
                <li>Term 2017-1</li>
                <li>Term 2015-2</li>
                <li>Term 2015-1</li>
                <li>Term 2014-2</li>
                <li>Term 2013-2</li>
              </ul>
            </dd>

          </td>
        </tr>
        <tr>
          <td colspan="2" style="border-bottom: 1px solid #e5e5e5; padding: 5px 0px;">
            <b>Teacher Assistant</b>
          </td>
        </tr>
        <tr>
          <td width="30px" style="vertical-align: top;  padding: 10px 10px;">
            <img src="assets/imgs/education/uob.png" width="30px" />
          </td>
          <td style="vertical-align: top;  padding: 10px 0px;">
            <b>University of Bristol</b>
            <br />
            Department of Engineering Mathematics
            <dl>
              <dd>
                Image Processing and Computer Vision
                <ul class="compact">
                  <li>2020-2021 Term 1</li>
                  <li>2021-2022 Term 1</li>
                  <li>2022-2023 Term 1</li>
                  <li>2023-2024 Term 1</li>
                </ul>
              </dd>
              <dd>
                Programing in C
                <ul class="compact">
                  <li>2022-2023 Term 1</li>
                  <li>2023-2024 Term 1</li>
                </ul>
              </dd>
              <dd>
                Object Oriented Programming
                <ul class="compact">
                  <li>2021-2022 Term 2</li>
                  <li>2022-2023 Term 2</li>
                </ul>
              </dd>
              <dd>
                Introduction to Computer Programming
                <ul class="compact">
                  <li>2020-2021 Term 1</li>
                  <li>2022-2023 Term 1</li>
                </ul>
              </dd>
              <dd>
                Further Computer Programming
                <ul class="compact">
                  <li>2020-2021 Term 2</li>
                  <li>2021-2022 Term 2</li>
                  <li>2022-2023 Term 2</li>
                </ul>
              </dd>

            </dl>

          </td>
        </tr>
      </table>

    </section>

    <footer>
      <p><small>Last update: <b>4 July 2025</b></a></small></p>
    </footer>
  </div>
  <script src="./assets/scale.fix.js"></script>


</body>

</html>